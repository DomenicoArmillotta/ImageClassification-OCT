{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGw929d0TdbM"
      },
      "source": [
        "Cose da fare e/o controllare : \n",
        "\n",
        "*  FARE  Test\n",
        "* provare con le pre trainate : inceptionv3 , mobilenet\n",
        "* capire se va meglio dopo aver fatto rescale 1/255\n",
        "\n",
        "https://www.tensorflow.org/tutorials/load_data/images?hl=it\n",
        "\n",
        "**Feature reuse** : \n",
        "This approach is typically used when the data and task being tackled are very different from the original task the pre-trained model was trained on.\n",
        "\n",
        "**Fine-tuning** : \n",
        " This approach is typically used when the data and task being tackled are similar to the original task the pre-trained model was trained on\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6yTVTSqNwje"
      },
      "source": [
        "[Dataset link](https://www.kaggle.com/datasets/paultimothymooney/kermany2018)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pay Attention** : Is used an organization of the code made to easy run the code to train"
      ],
      "metadata": {
        "id": "eAU-KYUWDH64"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RD4i_zUEVX2p"
      },
      "source": [
        "# **Library + Class weight**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pn7K-P65Nve3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.python.keras.layers import Dense\n",
        "from tensorflow.python.keras.layers import Flatten\n",
        "from tensorflow.python.keras.layers import Dropout\n",
        "from sklearn.metrics import accuracy_score\n",
        "np.random.seed(42)\n",
        "from google.colab import drive\n",
        "\n",
        "from matplotlib import style\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import cv2\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Input, Activation, add, Add, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
        "from keras.models import Sequential, Model\n",
        "from keras import optimizers\n",
        "\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lr9pme01gwwm"
      },
      "source": [
        "Distribution of the class inside the folder , without using np array\n",
        "\n",
        "is pretty fast --> 5s\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setup directory used in the project for training and test phase\n",
        "drive.mount('/content/drive')\n",
        "data_dir = '/content/drive/MyDrive/dataset/OCT/'\n",
        "train_dir = '/content/drive/MyDrive/dataset/OCT/train'\n",
        "test_dir = '/content/drive/MyDrive/dataset/OCT/test'\n",
        "val_dir = '/content/drive/MyDrive/dataset/OCT/val'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbbQ4XNhLvsQ",
        "outputId": "7c25a64c-b539-47eb-bddb-005a7f2fc131"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Ms6x4iYgoyK"
      },
      "outputs": [],
      "source": [
        "#compute class weight train for inbalanced dataset --> estimated time for 80k documents = 3s\n",
        "\n",
        "import pathlib\n",
        "\n",
        "# create array with all classes in the train\n",
        "summary = pd.DataFrame()\n",
        "val_classes = [item.name for item in \n",
        "                 pathlib.Path('/content/drive/MyDrive/dataset/OCT/train').glob('*')]\n",
        "\n",
        "# count the number of files in each folder\n",
        "# print(val_classes)\n",
        "for d in ['train']:\n",
        "    for c in val_classes:\n",
        "        n = len([i for i in pathlib.Path(f'/content/drive/MyDrive/dataset/OCT/{d}/{c}').glob('*')])\n",
        "        summary.loc[c, d] = n\n",
        "summary.style.format(\"{:.0f}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPIp6DKig11l"
      },
      "source": [
        "Compue class_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbZJcoKz-p2s",
        "outputId": "6880846b-4816-4c17-b779-61a70e8007b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37214/37214 [00:00<00:00, 1233897.73it/s]\n",
            "100%|██████████| 11348/11348 [00:00<00:00, 1279901.09it/s]\n",
            "100%|██████████| 8616/8616 [00:00<00:00, 1385026.95it/s]\n",
            "100%|██████████| 26315/26315 [00:00<00:00, 1337726.16it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.7932072962188865,\n",
              " 1: 0.5608977804052239,\n",
              " 2: 1.839376982728234,\n",
              " 3: 2.4226149025069637}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "train_directory = '/content/drive/MyDrive/dataset/OCT/train/'\n",
        "\n",
        "# ['DME', 'CNV', 'NORMAL', '.DS_Store', 'DRUSEN']\n",
        "from tqdm import tqdm\n",
        "def get_data(folder):\n",
        "    \"\"\"\n",
        "    Load the data and labels from the given folder.\n",
        "    \"\"\"\n",
        "    X = []\n",
        "    y = []\n",
        "    for folderName in os.listdir(folder):\n",
        "        if not folderName.startswith('.'):\n",
        "            if folderName in ['NORMAL']:\n",
        "                label = 0\n",
        "            elif folderName in ['CNV']:\n",
        "                label = 1\n",
        "            elif folderName in ['DME']:\n",
        "                label = 2\n",
        "            elif folderName in ['DRUSEN']:\n",
        "                label = 3\n",
        "            else:\n",
        "                label = 4\n",
        "            for image_filename in tqdm(os.listdir(folder + folderName)):\n",
        "                y.append(label)\n",
        "    y = np.asarray(y)\n",
        "    return y\n",
        "y_train= get_data(train_directory)\n",
        "\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "y_trainHot = to_categorical(y_train, num_classes = 4)\n",
        "\n",
        "from sklearn.utils import class_weight\n",
        "class_weight = class_weight.compute_class_weight(class_weight = \"balanced\", classes = np.unique(y_train),y =  y_train)\n",
        "class_weights = dict(zip(np.unique(y_train), class_weight))\n",
        "class_weights\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVgC1tgRxYVC"
      },
      "source": [
        "# **1. ALEXNET from scratch**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb6d69c6-606c-4424-f282-26fd8d190eb0",
        "id": "qIHeabC3A73A"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# setup directory used in the project for training and test phase\n",
        "drive.mount('/content/drive')\n",
        "data_dir = '/content/drive/MyDrive/dataset/OCT/'\n",
        "train_dir = '/content/drive/MyDrive/dataset/OCT/train'\n",
        "test_dir = '/content/drive/MyDrive/dataset/OCT/test'\n",
        "val_dir = '/content/drive/MyDrive/dataset/OCT/val/'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    class_names=None,\n",
        "    color_mode='grayscale',  #greyscale = 1 channel image\n",
        "    batch_size=128,          \n",
        "    image_size=(50, 50),     #qui le dim dell'immagine , da esperimenti risulta che se cambiamo a 150 non cambia troppo il tempo di train\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    validation_split=None,  #abbiamo gia il validation set\n",
        "    subset=None,\n",
        "    interpolation='bilinear',\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "val = tf.keras.utils.image_dataset_from_directory(\n",
        "    val_dir,\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    class_names=None,\n",
        "    color_mode='grayscale',\n",
        "    batch_size=128,\n",
        "    image_size=(50, 50),\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        "    interpolation='bilinear',\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IS6wc7JDBByX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#usato per la normalizzazzione -> lo fa keras negli esempi -> velocizza il training\n",
        "normalization_layer = tf.keras.layers.Rescaling(1./255)    \n",
        "val = val.map(lambda x, y: (normalization_layer(x), y))\n",
        "train = train.map(lambda x, y: (normalization_layer(x), y))\n"
      ],
      "metadata": {
        "id": "bJrk-LYABHa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mantiene le immagini in memoria dopo che sono state caricate dal disco durante la prima epoca. Velocizza il training\n",
        "#lo fa keras negli esempi\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train = train.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val = val.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "UN3xf4gjBJio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_yRfRhtxdh8"
      },
      "outputs": [],
      "source": [
        "#Early stopping -> nel caso da sistemare \n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_prc', \n",
        "    verbose=1,\n",
        "    patience=10,\n",
        "    mode='max',\n",
        "    restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfc6Lk2exsW5",
        "outputId": "619cab52-147b-4496-cba9-b48a94a89a24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 48, 48, 32)        320       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 48, 48, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 24, 24, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 24, 24, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 22, 22, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 22, 22, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 11, 11, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 11, 11, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 9, 9, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 9, 9, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 4, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 2, 2, 256)         295168    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 2, 2, 256)        1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 1, 1, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 1, 1, 256)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               131584    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 4)                 2052      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 786,052\n",
            "Trainable params: 785,092\n",
            "Non-trainable params: 960\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "img_size = 50\n",
        "model = keras.models.Sequential()\n",
        "#1st Convolutional Layer\n",
        "model.add(keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu', input_shape = [img_size, img_size,1]))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(keras.layers.Dropout(0.2))\n",
        "#2nd Convolutional Layer\n",
        "model.add(keras.layers.Conv2D(filters=64,kernel_size=3,activation='relu'))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(keras.layers.Dropout(0.2))\n",
        "#3rd Convolutional Layer\n",
        "model.add(keras.layers.Conv2D(filters=128,kernel_size=3,activation='relu'))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(keras.layers.Dropout(0.2))\n",
        "#4th Convolutional Layer\n",
        "model.add(keras.layers.Conv2D(filters=256,kernel_size=3,activation='relu'))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(keras.layers.Dropout(0.2))\n",
        "#Passing it to a Fully Connected layer\n",
        "model.add(keras.layers.Flatten())\n",
        "\n",
        "# 1st Fully Connected Layer\n",
        "model.add(keras.layers.Dense(512,activation='relu'))\n",
        "\n",
        "# 2st Fully Connected Layer\n",
        "model.add(keras.layers.Dense(512,activation='relu'))\n",
        "\n",
        "#Softmax layer for output\n",
        "model.add(keras.layers.Dense(4,activation='softmax'))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iz2u4wsGRv6x"
      },
      "source": [
        "### Training **Senza** Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "JIuDgya1x3FN",
        "outputId": "d42b5af5-a5c2-47d7-a76a-f7efe5884a76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            " 68/150 [============>.................] - ETA: 36:44 - loss: 1.3959 - accuracy: 0.6013"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-e14ed6388b94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m               metrics=['accuracy'])\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m       (concrete_function,\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train, epochs=12, validation_data=val ,steps_per_epoch=150 , verbose = 1 , callbacks=[early_stopping] , class_weight = class_weights)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/model/AlexNet_noAUG.h5')   # always save your weights after training or during training\n",
        "#evaluation with history\n",
        "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gIQ2A8wsE77V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#disconnessione per non consumare risorse\n",
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "vQduiJm_FGDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOhAx5JqRgm1"
      },
      "source": [
        "### Training **Con** Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_irqhW5Rm50"
      },
      "outputs": [],
      "source": [
        "#Augmentation --> farlo con il layer\n",
        "aug = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    zoom_range=0.15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.15,\n",
        "    horizontal_flip=False,\n",
        "    vertical_flip=False,\n",
        "    fill_mode=\"nearest\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DgxvI9CRj9k"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "img_height = 50\n",
        "batch_size=32\n",
        "epochs = 20\n",
        "model.fit(aug.flow_from_directory(directory=train_dir,target_size=(img_height, img_height),batch_size=batch_size ,shuffle=True,color_mode='grayscale',seed=None,class_mode='categorical'),\n",
        "          epochs=epochs,\n",
        "          validation_data=val,\n",
        "          class_weight = class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqKHhndx0lFK"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/model/AlexNet_AUG.h5')   # always save your weights after training or during training\n",
        "#evaluation with history\n",
        "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#disconnessione per non consumare risorse\n",
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "l_KExmJYCXON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_-tCbAQ6jrV"
      },
      "source": [
        "# **2. MNIST from scratch**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setup directory used in the project for training and test phase\n",
        "drive.mount('/content/drive')\n",
        "data_dir = '/content/drive/MyDrive/dataset/OCT/'\n",
        "train_dir = '/content/drive/MyDrive/dataset/OCT/train'\n",
        "test_dir = '/content/drive/MyDrive/dataset/OCT/test'\n",
        "val_dir = '/content/drive/MyDrive/dataset/OCT/val/'"
      ],
      "metadata": {
        "id": "Dtg5VUABBiXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    class_names=None,\n",
        "    color_mode='grayscale',\n",
        "    batch_size=128,\n",
        "    image_size=(50, 50),\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        "    interpolation='bilinear',\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "val = tf.keras.utils.image_dataset_from_directory(\n",
        "    val_dir,\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    class_names=None,\n",
        "    color_mode='grayscale',\n",
        "    batch_size=128,\n",
        "    image_size=(50, 50),\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        "    interpolation='bilinear',\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "yU1WUrZEBjFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
        "val = val.map(lambda x, y: (normalization_layer(x), y))\n",
        "train = train.map(lambda x, y: (normalization_layer(x), y))\n"
      ],
      "metadata": {
        "id": "FDmLMvD2BrGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mantiene le immagini in memoria dopo che sono state caricate dal disco durante la prima epoca. Velocizza il training\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train = train.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val = val.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "OwuHzOuzBrSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Early stopping\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_prc', \n",
        "    verbose=1,\n",
        "    patience=10,\n",
        "    mode='max',\n",
        "    restore_best_weights=True)"
      ],
      "metadata": {
        "id": "slNS-YM6BrX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Augmentation --> farlo con il layer\n",
        "aug = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    zoom_range=0.15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.15,\n",
        "    horizontal_flip=False,\n",
        "    vertical_flip=False,\n",
        "    fill_mode=\"nearest\")"
      ],
      "metadata": {
        "id": "BUHXiX3_Brac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Roo_mGsb6m1c",
        "outputId": "9bded1d9-26d2-4dcf-9d31-62fce9645e93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 48, 48, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 24, 24, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 22, 22, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 11, 11, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 9, 9, 128)         73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 4, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 250)               512250    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 1004      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 605,926\n",
            "Trainable params: 605,926\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "#we made the model with the augmentation layer\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu', input_shape = [50, 50,1]))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(keras.layers.Conv2D(filters=64 , activation='relu',kernel_size=3))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(keras.layers.Conv2D(filters=128 , activation='relu' ,kernel_size=3))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "model.add(keras.layers.Dense(250,activation='relu'))\n",
        "model.add(keras.layers.Dense(4,activation='softmax'))\n",
        "model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train **senza** augmentation"
      ],
      "metadata": {
        "id": "ePPuw6kzCNoI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bmkamEP64ZM",
        "outputId": "39859f35-d9c3-4a09-d013-bb4bd530c360"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "150/150 [==============================] - 2311s 13s/step - loss: 1.3722 - accuracy: 0.4941 - val_loss: 1.2377 - val_accuracy: 0.5000\n",
            "Epoch 2/8\n",
            "150/150 [==============================] - 1883s 13s/step - loss: 1.0494 - accuracy: 0.6640 - val_loss: 0.9739 - val_accuracy: 0.5000\n",
            "Epoch 3/8\n",
            "150/150 [==============================] - 2039s 14s/step - loss: 0.9520 - accuracy: 0.6917 - val_loss: 0.8526 - val_accuracy: 0.5625\n",
            "Epoch 4/8\n",
            "150/150 [==============================] - 2298s 15s/step - loss: 0.8734 - accuracy: 0.7266 - val_loss: 0.7811 - val_accuracy: 0.6250\n",
            "Epoch 5/8\n",
            " 53/150 [=========>....................] - ETA: 16:41 - loss: 0.8313 - accuracy: 0.7469"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1200 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r150/150 [==============================] - 550s 4s/step - loss: 0.8313 - accuracy: 0.7469 - val_loss: 0.7957 - val_accuracy: 0.5938\n"
          ]
        }
      ],
      "source": [
        "#train senza augmentation\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy']\n",
        "              )\n",
        "\n",
        "history = model.fit(train, epochs=8, validation_data=val , verbose = 1 , steps_per_epoch=150 ,  class_weight = class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PN0aLKv7A5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "outputId": "c4f5c172-04d6-424c-8ad5-f965bf8944d5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "model.save('/content/drive/MyDrive/dataset/model/MNIST.h5')   # always save your weights after training or during training\n",
        "#evaluation with history\n",
        "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#disconnessione per non consumare risorse\n",
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "ljXgyCt1CvTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZoh6L2MUD93"
      },
      "source": [
        "# **3. EFFICENT NET pre trained**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setup directory used in the project for training and test phase\n",
        "drive.mount('/content/drive')\n",
        "data_dir = '/content/drive/MyDrive/dataset/OCT/'\n",
        "train_dir = '/content/drive/MyDrive/dataset/OCT/train'\n",
        "test_dir = '/content/drive/MyDrive/dataset/OCT/test'\n",
        "val_dir = '/content/drive/MyDrive/dataset/OCT/val'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaGLzHBhLszy",
        "outputId": "0c751d06-0f7e-4159-9f0d-7b07c742d754"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuzuzRg4YDJu",
        "outputId": "3278be46-3b86-4a62-a7d3-a607a88a64f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 83493 files belonging to 4 classes.\n",
            "Found 32 files belonging to 4 classes.\n",
            "Found 83493 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "#Augmentation --> farlo con il layer\n",
        "\n",
        "m_channels = 3\n",
        "train = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    class_names=None,\n",
        "    color_mode='rgb', #--> attenzione a questo valore , con efficentnet per forza rgb\n",
        "    batch_size=64,\n",
        "    image_size=(150, 150),\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        "    interpolation='bilinear',\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False\n",
        ")\n",
        "\n",
        "val = tf.keras.utils.image_dataset_from_directory(\n",
        "    val_dir,\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    class_names=None,\n",
        "    color_mode='rgb',\n",
        "    batch_size=64,\n",
        "    image_size=(150, 150),\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        "    interpolation='bilinear',\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False\n",
        ")\n",
        "\n",
        "aug = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    zoom_range=0.15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.15,\n",
        "    horizontal_flip=False,\n",
        "    vertical_flip=False,\n",
        "    fill_mode=\"nearest\")\n",
        "\n",
        "img_dim = 150\n",
        "batch_size=64\n",
        "train_augmented = aug.flow_from_directory(\n",
        "    directory=train_dir,\n",
        "    target_size=(img_dim, img_dim),\n",
        "    batch_size=batch_size ,\n",
        "    shuffle=True,\n",
        "    color_mode='rgb',\n",
        "    seed=None,\n",
        "    class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#usato per la normalizzazzione -> lo fa keras negli esempi -> velocizza il training\n",
        "normalization_layer = tf.keras.layers.Rescaling(1./255)    \n",
        "val = val.map(lambda x, y: (normalization_layer(x), y))\n",
        "train = train.map(lambda x, y: (normalization_layer(x), y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZi6tFrjRaTB",
        "outputId": "a01c93b0-2aed-43a6-b052-18589f458d93"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mantiene le immagini in memoria dopo che sono state caricate dal disco durante la prima epoca. Velocizza il training\n",
        "#lo fa keras negli esempi\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train = train.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val = val.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "cFPhJTE-RaXt"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mFzvW2cckSg",
        "outputId": "87394d56-ef64-4784-8c3c-4e76ed44657b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16705208/16705208 [==============================] - 2s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnetb0 (Functional)  (None, 5, 5, 1280)       4049571   \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 1280)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1280)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4)                 5124      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,054,695\n",
            "Trainable params: 5,124\n",
            "Non-trainable params: 4,049,571\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Create Model\n",
        "img_dim = 150\n",
        "m_channels = 3\n",
        "model_ENB0 = EfficientNetB0(include_top=False, weights='imagenet', input_shape=(img_dim,img_dim,m_channels))\n",
        "model_ENB0.trainable = False\n",
        "CLASSES = 4\n",
        "model = Sequential()\n",
        "model.add(model_ENB0)\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(CLASSES,activation=\"softmax\"))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **OPTION 1 = Feature Reuse Training**"
      ],
      "metadata": {
        "id": "0ZLNxjXWDH3J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "971QXTw0dcXZ",
        "outputId": "0720dade-cf23-4fab-eab7-cad67134e001"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "150/150 [==============================] - ETA: 0s - loss: 1.2770 - accuracy: 0.5889"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_prc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r150/150 [==============================] - 1797s 9s/step - loss: 1.2770 - accuracy: 0.5889 - val_loss: 1.0849 - val_accuracy: 0.5625\n",
            "Epoch 2/15\n",
            "150/150 [==============================] - ETA: 0s - loss: 1.2280 - accuracy: 0.6204"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_prc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r150/150 [==============================] - 1337s 9s/step - loss: 1.2280 - accuracy: 0.6204 - val_loss: 1.1895 - val_accuracy: 0.6875\n",
            "Epoch 3/15\n",
            " 76/150 [==============>...............] - ETA: 11:07 - loss: 1.2343 - accuracy: 0.6155"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-d1316873de4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# without augmentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m       (concrete_function,\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#Early stopping\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_prc', \n",
        "    verbose=1,\n",
        "    patience=10,\n",
        "    mode='max',\n",
        "    restore_best_weights=True)\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = optimizers.Adam(learning_rate=1e-2),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# with augmentation \n",
        "# history = model.fit(train_augmented, epochs=5 , validation_data=val , verbose = 1 , callbacks=[early_stopping] , class_weight = class_weights)\n",
        "\n",
        "# without augmentation \n",
        "history = model.fit(train, epochs=15 , validation_data=val ,steps_per_epoch=150, verbose = 1 , callbacks=[early_stopping] , class_weight = class_weights)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBYtrY-HeUMW"
      },
      "outputs": [],
      "source": [
        "#evaluation with history\n",
        "model.save('/content/drive/MyDrive/model/efficent_featurereuse.h5')   # always save your weights after training or during training\n",
        "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#disconnessione per non sprecare risorse\n",
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "F4HtRfUuEBP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **OPTION 2 = fine tuning training**"
      ],
      "metadata": {
        "id": "q_5O8b_ADTvn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "CQjTTI9EeWIo"
      },
      "outputs": [],
      "source": [
        "# Freezing all layers until the fifth from the last\n",
        "model_ENB0.trainable = True\n",
        "for layer in model_ENB0.layers[:-5]:\n",
        " layer.trainable = False\n",
        "\n",
        " \n",
        "# model_ENB0.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXqSsgjVe_2R",
        "outputId": "e14b6c30-823a-48ee-d701-ef24bd4b7688"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "100/100 [==============================] - 1766s 18s/step - loss: 1.6115 - accuracy: 0.3122 - val_loss: 8.1276 - val_accuracy: 0.2500\n",
            "Epoch 2/20\n",
            "  2/100 [..............................] - ETA: 40:16 - loss: 1.5369 - accuracy: 0.3125"
          ]
        }
      ],
      "source": [
        "#Early stopping\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', \n",
        "    verbose=1,\n",
        "    patience=10,\n",
        "    mode='max',\n",
        "    restore_best_weights=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Pre Training\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = optimizers.Adam(learning_rate=1e-2),\n",
        "              metrics=['accuracy'])\n",
        " \n",
        "# epochs = 20  # @param {type: \"slider\", min:10, max:100}\n",
        "\n",
        "#history = model.fit(train_augmented, epochs=epochs ,steps_per_epoch=100, validation_data=val , verbose = 1 , callbacks=[early_stopping] , class_weight = class_weights)\n",
        "history = model.fit(train, epochs=epochs ,steps_per_epoch=100, validation_data=val , verbose = 1 , callbacks=[early_stopping] , class_weight = class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dw05uscfGlp"
      },
      "outputs": [],
      "source": [
        "#evaluation with history\n",
        "model.save('/content/drive/MyDrive/model/efficent_finetuning.h5')   # always save your weights after training or during training\n",
        "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#disconnessione per non sprecare risorse\n",
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "y09zXDsazxhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMZ_W8ypiX69"
      },
      "source": [
        "# **4. INCEPTION V3 pre-trained**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TV0zFR5vlLsE"
      },
      "source": [
        "[esempio](https://github.com/tejanirla/image_classification/blob/master/transfer_learning.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setup directory used in the project for training and test phase\n",
        "drive.mount('/content/drive')\n",
        "data_dir = '/content/drive/MyDrive/dataset/OCT/'\n",
        "train_dir = '/content/drive/MyDrive/dataset/OCT/train'\n",
        "test_dir = '/content/drive/MyDrive/dataset/OCT/test'\n",
        "val_dir = '/content/drive/MyDrive/dataset/OCT/val'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_jO3HQORN-h",
        "outputId": "db18c22c-67e0-4502-d58b-1bd33f5a53e2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Augmentation --> farlo con il layer\n",
        "\n",
        "m_channels = 3\n",
        "train = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    class_names=None,\n",
        "    color_mode='rgb', #--> attenzione a questo valore , con efficentnet per forza rgb\n",
        "    batch_size=64,\n",
        "    image_size=(150, 150),\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        "    interpolation='bilinear',\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False\n",
        ")\n",
        "\n",
        "val = tf.keras.utils.image_dataset_from_directory(\n",
        "    val_dir,\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    class_names=None,\n",
        "    color_mode='rgb',\n",
        "    batch_size=64,\n",
        "    image_size=(150, 150),\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        "    interpolation='bilinear',\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False\n",
        ")\n",
        "\n",
        "aug = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    zoom_range=0.15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.15,\n",
        "    horizontal_flip=False,\n",
        "    vertical_flip=False,\n",
        "    fill_mode=\"nearest\")\n",
        "\n",
        "img_dim = 150\n",
        "batch_size=64\n",
        "train_augmented = aug.flow_from_directory(\n",
        "    directory=train_dir,\n",
        "    target_size=(img_dim, img_dim),\n",
        "    batch_size=batch_size ,\n",
        "    shuffle=True,\n",
        "    color_mode='rgb',\n",
        "    seed=None,\n",
        "    class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51GwObqIROKa",
        "outputId": "cb031067-dba3-4590-fcb8-c7581bfc1510"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 83493 files belonging to 4 classes.\n",
            "Found 32 files belonging to 4 classes.\n",
            "Found 83493 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#usato per la normalizzazzione -> lo fa keras negli esempi -> velocizza il training\n",
        "normalization_layer = tf.keras.layers.Rescaling(1./255)    \n",
        "val = val.map(lambda x, y: (normalization_layer(x), y))\n",
        "train = train.map(lambda x, y: (normalization_layer(x), y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhbXgAfnRnP0",
        "outputId": "cb852b18-b2c1-436b-aefc-dbe5fe9bb297"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mantiene le immagini in memoria dopo che sono state caricate dal disco durante la prima epoca. Velocizza il training\n",
        "#lo fa keras negli esempi\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train = train.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val = val.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "CSKrzDOWRnrQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3"
      ],
      "metadata": {
        "id": "dswVsuBwQsPw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), # Shape of our images\n",
        "                                include_top = False, # Leave out the last fully connected layer\n",
        "                                weights = 'imagenet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VffUQqasQyBG",
        "outputId": "a785afda-2e53-4b09-bdc2-16bb9d1eab94"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 5s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False"
      ],
      "metadata": {
        "id": "ca6rUaI7Q0P7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.959):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True"
      ],
      "metadata": {
        "id": "D0A-mknzQ2Hl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7') #Only use layers including and above 'mixed7'\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__FK590qQ6KF",
        "outputId": "ae19d979-d981-4665-ae4a-1f1f717f1149"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "last layer output shape:  (None, 7, 7, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "\n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (4, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bR4-uUL5RHy8",
        "outputId": "55a2c16e-8dbf-4ed5-f32a-1bbc38d320a5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "last layer output shape:  (None, 7, 7, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = myCallback()\n",
        "history = model.fit(\n",
        "            train,\n",
        "            validation_data = val,\n",
        "            steps_per_epoch = 100,\n",
        "            epochs = 23,\n",
        "            validation_steps = 50,\n",
        "            verbose = 2,\n",
        "            callbacks=[callbacks])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0HUgVjCRKGA",
        "outputId": "0a715faa-e385-4ab3-ef59-a21b3d0c6516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "model.save('/content/drive/MyDrive/model/inceptionv3_featurereuse.h5')   # always save your weights after training or during training\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FbB21eGsRMkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MOBILE NET - pre trained** --> da fare"
      ],
      "metadata": {
        "id": "tkYpz2_XTI0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setup directory used in the project for training and test phase\n",
        "drive.mount('/content/drive')\n",
        "data_dir = '/content/drive/MyDrive/dataset/OCT/'\n",
        "train_dir = '/content/drive/MyDrive/dataset/OCT/train'\n",
        "test_dir = '/content/drive/MyDrive/dataset/OCT/test'\n",
        "val_dir = '/content/drive/MyDrive/dataset/OCT/val'"
      ],
      "metadata": {
        "id": "aVtCKLQtTM9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Augmentation --> farlo con il layer\n",
        "\n",
        "m_channels = 3\n",
        "train = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    class_names=None,\n",
        "    color_mode='rgb', #--> attenzione a questo valore , con efficentnet per forza rgb\n",
        "    batch_size=64,\n",
        "    image_size=(150, 150),\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        "    interpolation='bilinear',\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False\n",
        ")\n",
        "\n",
        "val = tf.keras.utils.image_dataset_from_directory(\n",
        "    val_dir,\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    class_names=None,\n",
        "    color_mode='rgb',\n",
        "    batch_size=64,\n",
        "    image_size=(150, 150),\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        "    interpolation='bilinear',\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False\n",
        ")\n",
        "\n",
        "aug = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    zoom_range=0.15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.15,\n",
        "    horizontal_flip=False,\n",
        "    vertical_flip=False,\n",
        "    fill_mode=\"nearest\")\n",
        "\n",
        "img_dim = 150\n",
        "batch_size=64\n",
        "train_augmented = aug.flow_from_directory(\n",
        "    directory=train_dir,\n",
        "    target_size=(img_dim, img_dim),\n",
        "    batch_size=batch_size ,\n",
        "    shuffle=True,\n",
        "    color_mode='rgb',\n",
        "    seed=None,\n",
        "    class_mode='categorical')"
      ],
      "metadata": {
        "id": "c33k4222TQmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#usato per la normalizzazzione -> lo fa keras negli esempi -> velocizza il training\n",
        "# The purpose of normalizing the pixel values is to ensure that the input data has a similar scale, which can help the model learn more effectively.\n",
        "normalization_layer = tf.keras.layers.Rescaling(1./255)    \n",
        "val = val.map(lambda x, y: (normalization_layer(x), y))\n",
        "train = train.map(lambda x, y: (normalization_layer(x), y))\n"
      ],
      "metadata": {
        "id": "ExpYzVJGTQoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mantiene le immagini in memoria dopo che sono state caricate dal disco durante la prima epoca. Velocizza il training\n",
        "#lo fa keras negli esempi\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train = train.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val = val.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "nInTwMJ0TQsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "84xOHJU6TQux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6db_lJxvTQzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. NEURAL NET from scratch - PROVA GIUSEPPE**"
      ],
      "metadata": {
        "id": "PMXLQsaHDzVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "Ns0ptuAshQFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup directory used in the project for training and test phase\n",
        "drive.mount('/content/drive')\n",
        "data_dir = '/content/drive/MyDrive/dataset/OCT/'\n",
        "train_dir = '/content/drive/MyDrive/dataset/OCT/train'\n",
        "test_dir = '/content/drive/MyDrive/dataset/OCT/test'\n",
        "val_dir = '/content/drive/MyDrive/dataset/OCT/val'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p64H9Bdnhh3p",
        "outputId": "f5b26751-59e2-4c70-875d-60d292b0aae6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sarebbe l'augmentation\n",
        "image_gen = ImageDataGenerator(rotation_range=25,\n",
        "                              width_shift_range=0.1,\n",
        "                              height_shift_range=0.1,rescale=1/255,shear_range=0.2,\n",
        "                              zoom_range=0.2,horizontal_flip=True,fill_mode='nearest')"
      ],
      "metadata": {
        "id": "nBWe4FSEhVEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', input_shape=(150, 150, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "optimizer = Adam(lr=0.001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SywX2Sjhpwr",
        "outputId": "27953209-a421-48a1-f4c2-c598462ef6bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_8 (Conv2D)           (None, 148, 148, 64)      640       \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 148, 148, 64)     256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 74, 74, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 72, 72, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 72, 72, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 36, 36, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 36, 36, 128)       0         \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 34, 34, 256)       295168    \n",
            "                                                                 \n",
            " batch_normalization_14 (Bat  (None, 34, 34, 256)      1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 17, 17, 256)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 17, 17, 256)       0         \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 15, 15, 512)       1180160   \n",
            "                                                                 \n",
            " batch_normalization_15 (Bat  (None, 15, 15, 512)      2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 7, 7, 512)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 512)               12845568  \n",
            "                                                                 \n",
            " batch_normalization_16 (Bat  (None, 512)              2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " batch_normalization_17 (Bat  (None, 512)              2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 4)                 2052      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,668,036\n",
            "Trainable params: 14,664,068\n",
            "Non-trainable params: 3,968\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_image_aug =image_gen.flow_from_directory(train_dir , target_size=(150,150),batch_size=64 , color_mode='grayscale')\n",
        "val_image_aug =image_gen.flow_from_directory(val_dir , target_size=(150,150),batch_size=64, color_mode='grayscale')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DE0myRQoiH8t",
        "outputId": "4ed04f3d-97c7-42cc-dff5-ed462218d1ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 83493 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "prova con gray scale e meno augmentation"
      ],
      "metadata": {
        "id": "D0bnQYzUpDWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_gen = ImageDataGenerator(rescale=1/255,shear_range=0,\n",
        "                              zoom_range=0,horizontal_flip=False,fill_mode='nearest')\n",
        "training_image_aug =image_gen.flow_from_directory(train_dir , target_size=(150,150),batch_size=64 , color_mode='grayscale')\n",
        "val_image_aug =image_gen.flow_from_directory(val_dir , target_size=(150,150),batch_size=64, color_mode='grayscale')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jm2__ucZiWLJ",
        "outputId": "8748aa61-adc7-4325-fde1-859074ec1ddc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 83493 images belonging to 4 classes.\n",
            "Found 32 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(training_image,\n",
        "                              steps_per_epoch=200,\n",
        "                              epochs=20,\n",
        "                              validation_data=val_image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "RjDm2WQIig12",
        "outputId": "9ec8c080-b4e6-4caa-b548-f00053ae9712"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-9e88e537afd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(training_image,\n\u001b[0m\u001b[1;32m      2\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                               validation_data=val_image)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m       (concrete_function,\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/model/Scrath3.h5')   # always save your weights after training or during training\n",
        "#evaluation with history\n",
        "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8XH3n8fQjmNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqkJAD250RLg"
      },
      "source": [
        "# **STOP - EXECUTE ALWAYS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOe9Kl-J0WNJ"
      },
      "outputs": [],
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "jVgC1tgRxYVC",
        "1_-tCbAQ6jrV",
        "ePPuw6kzCNoI",
        "CZoh6L2MUD93",
        "0ZLNxjXWDH3J",
        "tkYpz2_XTI0V",
        "PMXLQsaHDzVj",
        "hqkJAD250RLg"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyMPPLx2De0tw/jb21wiGWfe"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}